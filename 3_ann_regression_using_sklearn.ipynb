{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Regression\n",
    "\n",
    "We'll use the same Boston Housing Dataset as we used in section **Basic ANN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CSM dataset.csv', sep=\";\")\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset.\n",
    "\n",
    "To be fair, let's use the same method as in the **Basic ANN** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Split data into train partition and test partition\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define simple MLP Model\n",
    "\n",
    "Let's use the same parameter also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 20\n",
    "learning_rate = 0.1\n",
    "n_iter = 2000\n",
    "\n",
    "model = MLPRegressor(random_state=1, max_iter=n_iter, hidden_layer_sizes=n_hidden, learning_rate_init=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=20, learning_rate_init=0.1, max_iter=2000,\n",
       "             random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3427680.46023324 3427680.46023324 3429381.53652892 3427680.46023324\n",
      " 3427680.46023324 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3429381.53652892 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3429381.53652892 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3427680.46023324 3427680.46023324 3429381.53652892 3427680.46023324\n",
      " 3427680.46023324 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3429381.53652892 3429381.53652892 3427680.46023324 3427680.46023324\n",
      " 3429381.53652892 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3429381.53652892 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3429381.53652892 3429381.53652892 3429381.53652892 3427680.46023324\n",
      " 3429381.53652892 3427680.46023324 3429381.53652892 3429381.53652892\n",
      " 3427680.46023324 3427680.46023324 3427680.46023324 3427680.46023324\n",
      " 3427680.46023324 3427680.46023324 3429381.53652892 3427680.46023324\n",
      " 3429381.53652892 3429381.53652892 3427680.46023324 3429381.53652892\n",
      " 3427680.46023324]\n",
      "[4.690000e+06 1.800000e+06 1.066000e+03 2.594000e+06 2.814900e+06\n",
      " 3.185900e+06 8.880000e+05 3.849000e+03 2.284000e+06 1.256460e+05\n",
      " 8.153000e+06 9.842000e+03 2.466000e+06 1.144400e+04 1.458600e+04\n",
      " 1.841000e+05 4.120000e+05 1.800000e+06 1.189000e+07 3.700000e+05\n",
      " 2.356000e+06 1.818778e+06 1.810000e+04 1.280000e+06 6.750000e+05\n",
      " 1.198000e+06 1.899400e+06 1.480000e+05 2.007000e+06 2.150000e+04\n",
      " 1.923800e+06 1.801000e+05 3.249250e+05 8.839043e+06 6.710000e+05\n",
      " 9.536000e+03 1.887000e+03 2.500000e+05 7.687000e+05 2.169730e+07\n",
      " 2.939000e+06 1.178300e+07 1.891977e+06 1.188000e+06 1.550500e+06\n",
      " 1.140000e+05 1.706400e+07 2.574800e+04 9.190000e+05 2.160000e+05\n",
      " 1.630000e+06 2.417000e+06 9.737600e+06 4.240000e+06 1.168000e+05\n",
      " 1.098800e+07 1.161000e+05]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19856083039363.508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "print(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is worse than our basic ANN. But, this is no model tuning at all! You can play with another params in the **MLPRegressor** function os scikit-learn."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
